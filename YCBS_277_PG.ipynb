{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YCBS_277_PG.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM9v4QmFy/Ep4j0sQpPZk8T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arbi11/YCBS-277/blob/master/YCBS_277_PG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wBH6TCa5_cV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d8b42a7-4dfe-4df0-ca4b-122c1a2b8eea"
      },
      "source": [
        "\"\"\"\n",
        "Simple policy gradient in Keras\n",
        "\n",
        "\"\"\"\n",
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras import utils as np_utils\n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "class Agent(object):\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, hidden_dims=[32, 32]):\n",
        "        \"\"\"Gym Playing Agent\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): the dimension of state.\n",
        "                Same as `env.observation_space.shape[0]`\n",
        "\n",
        "            output_dim (int): the number of discrete actions\n",
        "                Same as `env.action_space.n`\n",
        "\n",
        "            hidden_dims (list): hidden dimensions\n",
        "\n",
        "        Methods:\n",
        "\n",
        "            private:\n",
        "                __build_train_fn -> None\n",
        "                    It creates a train function\n",
        "                    It's similar to defining `train_op` in Tensorflow\n",
        "                __build_network -> None\n",
        "                    It create a base model\n",
        "                    Its output is each action probability\n",
        "\n",
        "            public:\n",
        "                get_action(state) -> action\n",
        "                fit(state, action, reward) -> None\n",
        "        \"\"\"\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.__build_network(input_dim, output_dim, hidden_dims)\n",
        "        self.__build_train_fn()\n",
        "\n",
        "    def __build_network(self, input_dim, output_dim, hidden_dims=[32, 32]):\n",
        "        \"\"\"Create a base network\"\"\"\n",
        "        self.X = layers.Input(shape=(input_dim,))\n",
        "        net = self.X\n",
        "\n",
        "        for h_dim in hidden_dims:\n",
        "            net = layers.Dense(h_dim)(net)\n",
        "            net = layers.Activation(\"relu\")(net)\n",
        "\n",
        "        net = layers.Dense(output_dim)(net)\n",
        "        net = layers.Activation(\"softmax\")(net)\n",
        "\n",
        "        self.model = Model(inputs=self.X, outputs=net)\n",
        "\n",
        "    def __build_train_fn(self):\n",
        "        \"\"\"Create a train function\n",
        "\n",
        "        It replaces `model.fit(X, y)` because we use the output of model and use it for training.\n",
        "\n",
        "        For example, we need action placeholder\n",
        "        called `action_one_hot` that stores, which action we took at state `s`.\n",
        "        Hence, we can update the same action.\n",
        "\n",
        "        This function will create\n",
        "        `self.train_fn([state, action_one_hot, discount_reward])`\n",
        "        which would train the model.\n",
        "\n",
        "        \"\"\"\n",
        "        action_prob_placeholder = self.model.output\n",
        "        action_onehot_placeholder = K.placeholder(shape=(None, self.output_dim),\n",
        "                                                  name=\"action_onehot\")\n",
        "        discount_reward_placeholder = K.placeholder(shape=(None,),\n",
        "                                                    name=\"discount_reward\")\n",
        "\n",
        "        action_prob = K.sum(action_prob_placeholder * action_onehot_placeholder, axis=1)\n",
        "        log_action_prob = K.log(action_prob)\n",
        "\n",
        "        loss = - log_action_prob * discount_reward_placeholder\n",
        "        loss = K.mean(loss)\n",
        "\n",
        "        adam = optimizers.Adam()\n",
        "\n",
        "        updates = adam.get_updates(params=self.model.trainable_weights,\n",
        "                                   loss=loss)\n",
        "\n",
        "        self.train_fn = K.function(inputs=[self.model.input,\n",
        "                                           action_onehot_placeholder,\n",
        "                                           discount_reward_placeholder],\n",
        "                                   outputs=[],\n",
        "                                   updates=updates)\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"Returns an action at given `state`\n",
        "\n",
        "        Args:\n",
        "            state (1-D or 2-D Array): It can be either 1-D array of shape (state_dimension, )\n",
        "                or 2-D array shape of (n_samples, state_dimension)\n",
        "\n",
        "        Returns:\n",
        "            action: an integer action value ranging from 0 to (n_actions - 1)\n",
        "        \"\"\"\n",
        "        shape = state.shape\n",
        "\n",
        "        if len(shape) == 1:\n",
        "            assert shape == (self.input_dim,), \"{} != {}\".format(shape, self.input_dim)\n",
        "            state = np.expand_dims(state, axis=0)\n",
        "\n",
        "        elif len(shape) == 2:\n",
        "            assert shape[1] == (self.input_dim), \"{} != {}\".format(shape, self.input_dim)\n",
        "\n",
        "        else:\n",
        "            raise TypeError(\"Wrong state shape is given: {}\".format(state.shape))\n",
        "\n",
        "        action_prob = np.squeeze(self.model.predict(state))\n",
        "        assert len(action_prob) == self.output_dim, \"{} != {}\".format(len(action_prob), self.output_dim)\n",
        "        return np.random.choice(np.arange(self.output_dim), p=action_prob)\n",
        "\n",
        "    def fit(self, S, A, R):\n",
        "        \"\"\"Train a network\n",
        "\n",
        "        Args:\n",
        "            S (2-D Array): `state` array of shape (n_samples, state_dimension)\n",
        "            A (1-D Array): `action` array of shape (n_samples,)\n",
        "                It's simply a list of int that stores which actions the agent chose\n",
        "            R (1-D Array): `reward` array of shape (n_samples,)\n",
        "                A reward is given after each action.\n",
        "\n",
        "        \"\"\"\n",
        "        action_onehot = np_utils.to_categorical(A, num_classes=self.output_dim)\n",
        "        discount_reward = compute_discounted_R(R)\n",
        "\n",
        "        assert S.shape[1] == self.input_dim, \"{} != {}\".format(S.shape[1], self.input_dim)\n",
        "        assert action_onehot.shape[0] == S.shape[0], \"{} != {}\".format(action_onehot.shape[0], S.shape[0])\n",
        "        assert action_onehot.shape[1] == self.output_dim, \"{} != {}\".format(action_onehot.shape[1], self.output_dim)\n",
        "        assert len(discount_reward.shape) == 1, \"{} != 1\".format(len(discount_reward.shape))\n",
        "\n",
        "        self.train_fn([S, action_onehot, discount_reward])\n",
        "\n",
        "\n",
        "def compute_discounted_R(R, discount_rate=.99):\n",
        "    \"\"\"Returns discounted rewards\n",
        "\n",
        "    Args:\n",
        "        R (1-D array): a list of `reward` at each time step\n",
        "        discount_rate (float): Will discount the future value by this rate\n",
        "\n",
        "    Returns:\n",
        "        discounted_r (1-D array): same shape as input `R`\n",
        "            but the values are discounted\n",
        "\n",
        "    Examples:\n",
        "        >>> R = [1, 1, 1]\n",
        "        >>> compute_discounted_R(R, .99) # before normalization\n",
        "        [1 + 0.99 + 0.99**2, 1 + 0.99, 1]\n",
        "    \"\"\"\n",
        "    discounted_r = np.zeros_like(R, dtype=np.float32)\n",
        "    running_add = 0\n",
        "    for t in reversed(range(len(R))):\n",
        "\n",
        "        running_add = running_add * discount_rate + R[t]\n",
        "        discounted_r[t] = running_add\n",
        "\n",
        "    discounted_r -= discounted_r.mean() / discounted_r.std()\n",
        "\n",
        "    return discounted_r\n",
        "\n",
        "\n",
        "def run_episode(env, agent):\n",
        "    \"\"\"Returns an episode reward\n",
        "\n",
        "    (1) Play until the game is done\n",
        "    (2) The agent will choose an action according to the policy\n",
        "    (3) When it's done, it will train from the game play\n",
        "\n",
        "    Args:\n",
        "        env (gym.env): Gym environment\n",
        "        agent (Agent): Game Playing Agent\n",
        "\n",
        "    Returns:\n",
        "        total_reward (int): total reward earned during the whole episode\n",
        "    \"\"\"\n",
        "    done = False\n",
        "    S = []\n",
        "    A = []\n",
        "    R = []\n",
        "\n",
        "    s = env.reset()\n",
        "\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        s2, r, done, info = env.step(a)\n",
        "        total_reward += r\n",
        "\n",
        "        S.append(s)\n",
        "        A.append(a)\n",
        "        R.append(r)\n",
        "\n",
        "        s = s2\n",
        "\n",
        "        if done:\n",
        "            S = np.array(S)\n",
        "            A = np.array(A)\n",
        "            R = np.array(R)\n",
        "\n",
        "            agent.fit(S, A, R)\n",
        "\n",
        "    return total_reward\n",
        "\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        env = gym.make(\"CartPole-v0\")\n",
        "        input_dim = env.observation_space.shape[0]\n",
        "        output_dim = env.action_space.n\n",
        "        agent = Agent(input_dim, output_dim, [16, 16])\n",
        "\n",
        "        for episode in range(2000):\n",
        "            reward = run_episode(env, agent)\n",
        "            print(episode, reward)\n",
        "\n",
        "    finally:\n",
        "        env.close()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "0 14.0\n",
            "1 21.0\n",
            "2 10.0\n",
            "3 36.0\n",
            "4 12.0\n",
            "5 10.0\n",
            "6 21.0\n",
            "7 14.0\n",
            "8 35.0\n",
            "9 35.0\n",
            "10 26.0\n",
            "11 41.0\n",
            "12 48.0\n",
            "13 51.0\n",
            "14 41.0\n",
            "15 13.0\n",
            "16 20.0\n",
            "17 14.0\n",
            "18 19.0\n",
            "19 22.0\n",
            "20 10.0\n",
            "21 73.0\n",
            "22 11.0\n",
            "23 80.0\n",
            "24 16.0\n",
            "25 19.0\n",
            "26 36.0\n",
            "27 58.0\n",
            "28 13.0\n",
            "29 10.0\n",
            "30 34.0\n",
            "31 21.0\n",
            "32 20.0\n",
            "33 11.0\n",
            "34 18.0\n",
            "35 18.0\n",
            "36 16.0\n",
            "37 33.0\n",
            "38 15.0\n",
            "39 23.0\n",
            "40 57.0\n",
            "41 16.0\n",
            "42 30.0\n",
            "43 34.0\n",
            "44 23.0\n",
            "45 29.0\n",
            "46 12.0\n",
            "47 43.0\n",
            "48 32.0\n",
            "49 34.0\n",
            "50 30.0\n",
            "51 68.0\n",
            "52 40.0\n",
            "53 23.0\n",
            "54 42.0\n",
            "55 18.0\n",
            "56 13.0\n",
            "57 20.0\n",
            "58 10.0\n",
            "59 21.0\n",
            "60 27.0\n",
            "61 24.0\n",
            "62 11.0\n",
            "63 16.0\n",
            "64 19.0\n",
            "65 18.0\n",
            "66 16.0\n",
            "67 15.0\n",
            "68 15.0\n",
            "69 26.0\n",
            "70 33.0\n",
            "71 16.0\n",
            "72 29.0\n",
            "73 31.0\n",
            "74 15.0\n",
            "75 39.0\n",
            "76 34.0\n",
            "77 51.0\n",
            "78 17.0\n",
            "79 23.0\n",
            "80 9.0\n",
            "81 25.0\n",
            "82 23.0\n",
            "83 25.0\n",
            "84 22.0\n",
            "85 49.0\n",
            "86 17.0\n",
            "87 46.0\n",
            "88 15.0\n",
            "89 32.0\n",
            "90 28.0\n",
            "91 27.0\n",
            "92 21.0\n",
            "93 12.0\n",
            "94 22.0\n",
            "95 12.0\n",
            "96 14.0\n",
            "97 14.0\n",
            "98 15.0\n",
            "99 15.0\n",
            "100 13.0\n",
            "101 29.0\n",
            "102 18.0\n",
            "103 41.0\n",
            "104 21.0\n",
            "105 31.0\n",
            "106 20.0\n",
            "107 19.0\n",
            "108 43.0\n",
            "109 109.0\n",
            "110 21.0\n",
            "111 43.0\n",
            "112 32.0\n",
            "113 37.0\n",
            "114 47.0\n",
            "115 29.0\n",
            "116 11.0\n",
            "117 24.0\n",
            "118 64.0\n",
            "119 94.0\n",
            "120 36.0\n",
            "121 19.0\n",
            "122 34.0\n",
            "123 43.0\n",
            "124 64.0\n",
            "125 37.0\n",
            "126 18.0\n",
            "127 10.0\n",
            "128 14.0\n",
            "129 36.0\n",
            "130 31.0\n",
            "131 22.0\n",
            "132 36.0\n",
            "133 24.0\n",
            "134 26.0\n",
            "135 25.0\n",
            "136 23.0\n",
            "137 24.0\n",
            "138 36.0\n",
            "139 41.0\n",
            "140 24.0\n",
            "141 53.0\n",
            "142 31.0\n",
            "143 42.0\n",
            "144 52.0\n",
            "145 34.0\n",
            "146 42.0\n",
            "147 22.0\n",
            "148 40.0\n",
            "149 16.0\n",
            "150 84.0\n",
            "151 15.0\n",
            "152 14.0\n",
            "153 34.0\n",
            "154 43.0\n",
            "155 14.0\n",
            "156 30.0\n",
            "157 93.0\n",
            "158 61.0\n",
            "159 68.0\n",
            "160 39.0\n",
            "161 52.0\n",
            "162 54.0\n",
            "163 85.0\n",
            "164 16.0\n",
            "165 35.0\n",
            "166 31.0\n",
            "167 26.0\n",
            "168 51.0\n",
            "169 17.0\n",
            "170 41.0\n",
            "171 32.0\n",
            "172 57.0\n",
            "173 62.0\n",
            "174 43.0\n",
            "175 109.0\n",
            "176 54.0\n",
            "177 31.0\n",
            "178 34.0\n",
            "179 16.0\n",
            "180 60.0\n",
            "181 35.0\n",
            "182 28.0\n",
            "183 20.0\n",
            "184 38.0\n",
            "185 20.0\n",
            "186 41.0\n",
            "187 44.0\n",
            "188 90.0\n",
            "189 42.0\n",
            "190 91.0\n",
            "191 48.0\n",
            "192 12.0\n",
            "193 52.0\n",
            "194 71.0\n",
            "195 29.0\n",
            "196 64.0\n",
            "197 29.0\n",
            "198 31.0\n",
            "199 23.0\n",
            "200 52.0\n",
            "201 60.0\n",
            "202 75.0\n",
            "203 20.0\n",
            "204 49.0\n",
            "205 17.0\n",
            "206 31.0\n",
            "207 48.0\n",
            "208 29.0\n",
            "209 29.0\n",
            "210 22.0\n",
            "211 34.0\n",
            "212 34.0\n",
            "213 68.0\n",
            "214 65.0\n",
            "215 119.0\n",
            "216 39.0\n",
            "217 34.0\n",
            "218 15.0\n",
            "219 54.0\n",
            "220 36.0\n",
            "221 26.0\n",
            "222 39.0\n",
            "223 39.0\n",
            "224 19.0\n",
            "225 54.0\n",
            "226 18.0\n",
            "227 18.0\n",
            "228 67.0\n",
            "229 23.0\n",
            "230 43.0\n",
            "231 19.0\n",
            "232 84.0\n",
            "233 23.0\n",
            "234 20.0\n",
            "235 62.0\n",
            "236 25.0\n",
            "237 27.0\n",
            "238 50.0\n",
            "239 24.0\n",
            "240 28.0\n",
            "241 12.0\n",
            "242 33.0\n",
            "243 21.0\n",
            "244 16.0\n",
            "245 18.0\n",
            "246 22.0\n",
            "247 13.0\n",
            "248 19.0\n",
            "249 18.0\n",
            "250 58.0\n",
            "251 28.0\n",
            "252 38.0\n",
            "253 24.0\n",
            "254 79.0\n",
            "255 16.0\n",
            "256 15.0\n",
            "257 17.0\n",
            "258 46.0\n",
            "259 36.0\n",
            "260 20.0\n",
            "261 41.0\n",
            "262 45.0\n",
            "263 17.0\n",
            "264 23.0\n",
            "265 72.0\n",
            "266 12.0\n",
            "267 88.0\n",
            "268 14.0\n",
            "269 74.0\n",
            "270 17.0\n",
            "271 40.0\n",
            "272 22.0\n",
            "273 55.0\n",
            "274 29.0\n",
            "275 23.0\n",
            "276 80.0\n",
            "277 25.0\n",
            "278 46.0\n",
            "279 121.0\n",
            "280 11.0\n",
            "281 47.0\n",
            "282 20.0\n",
            "283 55.0\n",
            "284 33.0\n",
            "285 49.0\n",
            "286 46.0\n",
            "287 125.0\n",
            "288 30.0\n",
            "289 76.0\n",
            "290 85.0\n",
            "291 30.0\n",
            "292 26.0\n",
            "293 66.0\n",
            "294 40.0\n",
            "295 46.0\n",
            "296 50.0\n",
            "297 15.0\n",
            "298 15.0\n",
            "299 52.0\n",
            "300 61.0\n",
            "301 61.0\n",
            "302 160.0\n",
            "303 45.0\n",
            "304 40.0\n",
            "305 88.0\n",
            "306 52.0\n",
            "307 45.0\n",
            "308 33.0\n",
            "309 64.0\n",
            "310 18.0\n",
            "311 37.0\n",
            "312 200.0\n",
            "313 13.0\n",
            "314 23.0\n",
            "315 80.0\n",
            "316 25.0\n",
            "317 14.0\n",
            "318 42.0\n",
            "319 105.0\n",
            "320 16.0\n",
            "321 84.0\n",
            "322 36.0\n",
            "323 58.0\n",
            "324 37.0\n",
            "325 131.0\n",
            "326 90.0\n",
            "327 165.0\n",
            "328 11.0\n",
            "329 29.0\n",
            "330 34.0\n",
            "331 35.0\n",
            "332 53.0\n",
            "333 20.0\n",
            "334 152.0\n",
            "335 66.0\n",
            "336 26.0\n",
            "337 69.0\n",
            "338 39.0\n",
            "339 58.0\n",
            "340 76.0\n",
            "341 56.0\n",
            "342 33.0\n",
            "343 21.0\n",
            "344 48.0\n",
            "345 52.0\n",
            "346 62.0\n",
            "347 21.0\n",
            "348 14.0\n",
            "349 40.0\n",
            "350 132.0\n",
            "351 64.0\n",
            "352 123.0\n",
            "353 32.0\n",
            "354 59.0\n",
            "355 16.0\n",
            "356 27.0\n",
            "357 29.0\n",
            "358 106.0\n",
            "359 51.0\n",
            "360 112.0\n",
            "361 64.0\n",
            "362 71.0\n",
            "363 140.0\n",
            "364 78.0\n",
            "365 120.0\n",
            "366 67.0\n",
            "367 200.0\n",
            "368 57.0\n",
            "369 44.0\n",
            "370 50.0\n",
            "371 123.0\n",
            "372 164.0\n",
            "373 194.0\n",
            "374 54.0\n",
            "375 37.0\n",
            "376 60.0\n",
            "377 40.0\n",
            "378 68.0\n",
            "379 27.0\n",
            "380 83.0\n",
            "381 98.0\n",
            "382 112.0\n",
            "383 99.0\n",
            "384 33.0\n",
            "385 82.0\n",
            "386 119.0\n",
            "387 44.0\n",
            "388 69.0\n",
            "389 100.0\n",
            "390 105.0\n",
            "391 60.0\n",
            "392 49.0\n",
            "393 44.0\n",
            "394 198.0\n",
            "395 13.0\n",
            "396 89.0\n",
            "397 27.0\n",
            "398 200.0\n",
            "399 130.0\n",
            "400 57.0\n",
            "401 91.0\n",
            "402 149.0\n",
            "403 53.0\n",
            "404 112.0\n",
            "405 57.0\n",
            "406 24.0\n",
            "407 163.0\n",
            "408 81.0\n",
            "409 200.0\n",
            "410 78.0\n",
            "411 39.0\n",
            "412 43.0\n",
            "413 41.0\n",
            "414 68.0\n",
            "415 92.0\n",
            "416 191.0\n",
            "417 73.0\n",
            "418 31.0\n",
            "419 72.0\n",
            "420 37.0\n",
            "421 62.0\n",
            "422 84.0\n",
            "423 77.0\n",
            "424 33.0\n",
            "425 36.0\n",
            "426 32.0\n",
            "427 47.0\n",
            "428 68.0\n",
            "429 54.0\n",
            "430 56.0\n",
            "431 105.0\n",
            "432 124.0\n",
            "433 119.0\n",
            "434 108.0\n",
            "435 53.0\n",
            "436 52.0\n",
            "437 41.0\n",
            "438 75.0\n",
            "439 72.0\n",
            "440 192.0\n",
            "441 36.0\n",
            "442 38.0\n",
            "443 200.0\n",
            "444 121.0\n",
            "445 25.0\n",
            "446 74.0\n",
            "447 107.0\n",
            "448 200.0\n",
            "449 127.0\n",
            "450 34.0\n",
            "451 92.0\n",
            "452 142.0\n",
            "453 58.0\n",
            "454 200.0\n",
            "455 75.0\n",
            "456 77.0\n",
            "457 50.0\n",
            "458 51.0\n",
            "459 100.0\n",
            "460 45.0\n",
            "461 84.0\n",
            "462 67.0\n",
            "463 29.0\n",
            "464 38.0\n",
            "465 111.0\n",
            "466 96.0\n",
            "467 33.0\n",
            "468 39.0\n",
            "469 116.0\n",
            "470 200.0\n",
            "471 30.0\n",
            "472 125.0\n",
            "473 50.0\n",
            "474 84.0\n",
            "475 85.0\n",
            "476 20.0\n",
            "477 68.0\n",
            "478 94.0\n",
            "479 97.0\n",
            "480 106.0\n",
            "481 59.0\n",
            "482 55.0\n",
            "483 38.0\n",
            "484 79.0\n",
            "485 200.0\n",
            "486 166.0\n",
            "487 75.0\n",
            "488 46.0\n",
            "489 116.0\n",
            "490 44.0\n",
            "491 116.0\n",
            "492 175.0\n",
            "493 200.0\n",
            "494 39.0\n",
            "495 58.0\n",
            "496 106.0\n",
            "497 75.0\n",
            "498 16.0\n",
            "499 136.0\n",
            "500 186.0\n",
            "501 64.0\n",
            "502 101.0\n",
            "503 200.0\n",
            "504 75.0\n",
            "505 200.0\n",
            "506 109.0\n",
            "507 191.0\n",
            "508 200.0\n",
            "509 148.0\n",
            "510 190.0\n",
            "511 200.0\n",
            "512 189.0\n",
            "513 39.0\n",
            "514 54.0\n",
            "515 71.0\n",
            "516 75.0\n",
            "517 83.0\n",
            "518 200.0\n",
            "519 200.0\n",
            "520 200.0\n",
            "521 170.0\n",
            "522 192.0\n",
            "523 200.0\n",
            "524 200.0\n",
            "525 200.0\n",
            "526 75.0\n",
            "527 171.0\n",
            "528 90.0\n",
            "529 200.0\n",
            "530 112.0\n",
            "531 87.0\n",
            "532 111.0\n",
            "533 169.0\n",
            "534 200.0\n",
            "535 108.0\n",
            "536 97.0\n",
            "537 200.0\n",
            "538 149.0\n",
            "539 114.0\n",
            "540 151.0\n",
            "541 41.0\n",
            "542 125.0\n",
            "543 200.0\n",
            "544 144.0\n",
            "545 136.0\n",
            "546 114.0\n",
            "547 200.0\n",
            "548 49.0\n",
            "549 163.0\n",
            "550 72.0\n",
            "551 110.0\n",
            "552 200.0\n",
            "553 200.0\n",
            "554 101.0\n",
            "555 200.0\n",
            "556 143.0\n",
            "557 200.0\n",
            "558 138.0\n",
            "559 200.0\n",
            "560 200.0\n",
            "561 177.0\n",
            "562 116.0\n",
            "563 167.0\n",
            "564 176.0\n",
            "565 200.0\n",
            "566 198.0\n",
            "567 200.0\n",
            "568 90.0\n",
            "569 189.0\n",
            "570 15.0\n",
            "571 70.0\n",
            "572 200.0\n",
            "573 199.0\n",
            "574 200.0\n",
            "575 173.0\n",
            "576 42.0\n",
            "577 200.0\n",
            "578 200.0\n",
            "579 200.0\n",
            "580 83.0\n",
            "581 200.0\n",
            "582 200.0\n",
            "583 87.0\n",
            "584 200.0\n",
            "585 200.0\n",
            "586 200.0\n",
            "587 60.0\n",
            "588 200.0\n",
            "589 200.0\n",
            "590 200.0\n",
            "591 200.0\n",
            "592 200.0\n",
            "593 200.0\n",
            "594 200.0\n",
            "595 110.0\n",
            "596 200.0\n",
            "597 70.0\n",
            "598 200.0\n",
            "599 200.0\n",
            "600 200.0\n",
            "601 141.0\n",
            "602 200.0\n",
            "603 87.0\n",
            "604 139.0\n",
            "605 200.0\n",
            "606 200.0\n",
            "607 200.0\n",
            "608 88.0\n",
            "609 84.0\n",
            "610 176.0\n",
            "611 143.0\n",
            "612 142.0\n",
            "613 200.0\n",
            "614 200.0\n",
            "615 81.0\n",
            "616 183.0\n",
            "617 43.0\n",
            "618 200.0\n",
            "619 51.0\n",
            "620 200.0\n",
            "621 200.0\n",
            "622 186.0\n",
            "623 133.0\n",
            "624 56.0\n",
            "625 200.0\n",
            "626 144.0\n",
            "627 168.0\n",
            "628 52.0\n",
            "629 200.0\n",
            "630 182.0\n",
            "631 200.0\n",
            "632 200.0\n",
            "633 200.0\n",
            "634 38.0\n",
            "635 87.0\n",
            "636 200.0\n",
            "637 200.0\n",
            "638 127.0\n",
            "639 42.0\n",
            "640 200.0\n",
            "641 145.0\n",
            "642 198.0\n",
            "643 102.0\n",
            "644 144.0\n",
            "645 81.0\n",
            "646 152.0\n",
            "647 200.0\n",
            "648 146.0\n",
            "649 122.0\n",
            "650 136.0\n",
            "651 191.0\n",
            "652 200.0\n",
            "653 120.0\n",
            "654 200.0\n",
            "655 154.0\n",
            "656 39.0\n",
            "657 192.0\n",
            "658 195.0\n",
            "659 200.0\n",
            "660 183.0\n",
            "661 200.0\n",
            "662 144.0\n",
            "663 137.0\n",
            "664 200.0\n",
            "665 200.0\n",
            "666 151.0\n",
            "667 200.0\n",
            "668 137.0\n",
            "669 136.0\n",
            "670 148.0\n",
            "671 43.0\n",
            "672 200.0\n",
            "673 145.0\n",
            "674 186.0\n",
            "675 200.0\n",
            "676 61.0\n",
            "677 200.0\n",
            "678 200.0\n",
            "679 93.0\n",
            "680 200.0\n",
            "681 132.0\n",
            "682 200.0\n",
            "683 198.0\n",
            "684 200.0\n",
            "685 95.0\n",
            "686 169.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni_W1Iem6BPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZeCCumg6klc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "706a8ea0-5328-4836-b685-9b028c865aaa"
      },
      "source": [
        "keras.__version__"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qf0djsS6tX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}